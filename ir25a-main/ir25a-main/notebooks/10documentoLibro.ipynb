{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1517ebfa",
   "metadata": {},
   "source": [
    "# Cargar el libro \n",
    "\n",
    "Hacer RAG con el libro proporcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1998b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\roble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b1974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Use raw string (r prefix) or forward slashes to avoid escape sequence issues\n",
    "doc = fitz.open(r\"C:\\Users\\roble\\OneDrive\\Documentos\\GitHub\\Recuperacion\\ir25a-main\\ir25a-main\\libro\\irbookonlinereading.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41e4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16ed3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>578</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>579</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page                                                raw\n",
       "0       1  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...\n",
       "1       2         b'Online edition (c)\\n2009 Cambridge UP\\n'\n",
       "2       3  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...\n",
       "3       4  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...\n",
       "4       5  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...\n",
       "..    ...                                                ...\n",
       "576   577  b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...\n",
       "577   578  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...\n",
       "578   579  b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...\n",
       "579   580  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...\n",
       "580   581  b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...\n",
       "\n",
       "[581 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for i, page in enumerate(doc):\n",
    "    text = page.get_text().encode('utf-8')\n",
    "    if text.strip():\n",
    "        data.append({\n",
    "            \"page\": i + 1,\n",
    "            \"raw\": str(text).strip()\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8583a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡El PDF tiene 256 elementos en la tabla de contenidos!\n",
      "\n",
      "Primeras 10 entradas:\n",
      "Nivel 1: List of Tables (Página 15)\n",
      "Nivel 1: List of Figures (Página 19)\n",
      "Nivel 1: Table of Notation (Página 27)\n",
      "Nivel 1: Preface (Página 31)\n",
      "Nivel 1: Boolean retrieval (Página 38)\n",
      "  Nivel 2: An example information retrieval problem (Página 40)\n",
      "  Nivel 2: A first take at building an inverted index (Página 43)\n",
      "  Nivel 2: Processing Boolean queries (Página 47)\n",
      "  Nivel 2: The extended Boolean model versus ranked retrieval (Página 51)\n",
      "  Nivel 2: References and further reading (Página 54)\n",
      "Nivel 1: The term vocabulary and postings lists (Página 56)\n",
      "  Nivel 2: Document delineation and character sequence decoding (Página 56)\n",
      "    Nivel 3: Obtaining the character sequence in a document (Página 56)\n",
      "    Nivel 3: Choosing a document unit (Página 57)\n",
      "  Nivel 2: Determining the vocabulary of terms (Página 59)\n",
      "    Nivel 3: Tokenization (Página 59)\n",
      "    Nivel 3: Dropping common terms: stop words (Página 64)\n",
      "    Nivel 3: Normalization (equivalence classing of terms) (Página 65)\n",
      "    Nivel 3: Stemming and lemmatization (Página 69)\n",
      "  Nivel 2: Faster postings list intersection via skip pointers (Página 73)\n",
      "  Nivel 2: Positional postings and phrase queries (Página 76)\n",
      "    Nivel 3: Biword indexes (Página 76)\n",
      "    Nivel 3: Positional indexes (Página 78)\n",
      "    Nivel 3: Combination schemes (Página 80)\n",
      "  Nivel 2: References and further reading (Página 82)\n",
      "Nivel 1: Dictionaries and tolerant retrieval (Página 86)\n",
      "  Nivel 2: Search structures for dictionaries (Página 86)\n",
      "  Nivel 2: Wildcard queries (Página 88)\n",
      "    Nivel 3: General wildcard queries (Página 90)\n",
      "    Nivel 3: k-gram indexes for wildcard queries (Página 91)\n",
      "  Nivel 2: Spelling correction (Página 93)\n",
      "    Nivel 3: Implementing spelling correction (Página 94)\n",
      "    Nivel 3: Forms of spelling correction (Página 94)\n",
      "    Nivel 3: Edit distance (Página 95)\n",
      "    Nivel 3: k-gram indexes for spelling correction (Página 97)\n",
      "    Nivel 3: Context sensitive spelling correction (Página 99)\n",
      "  Nivel 2: Phonetic correction (Página 100)\n",
      "  Nivel 2: References and further reading (Página 102)\n",
      "Nivel 1: Index construction (Página 104)\n",
      "  Nivel 2: Hardware basics (Página 105)\n",
      "  Nivel 2: Blocked sort-based indexing (Página 106)\n",
      "  Nivel 2: Single-pass in-memory indexing (Página 110)\n",
      "  Nivel 2: Distributed indexing (Página 111)\n",
      "  Nivel 2: Dynamic indexing (Página 115)\n",
      "  Nivel 2: Other types of indexes (Página 117)\n",
      "  Nivel 2: References and further reading (Página 120)\n",
      "Nivel 1: Index compression (Página 122)\n",
      "  Nivel 2: Statistical properties of terms in information retrieval (Página 123)\n",
      "    Nivel 3: Heaps' law: Estimating the number of terms (Página 125)\n",
      "    Nivel 3: Zipf's law: Modeling the distribution of terms (Página 126)\n",
      "  Nivel 2: Dictionary compression (Página 127)\n",
      "    Nivel 3: Dictionary as a string (Página 128)\n",
      "    Nivel 3: Blocked storage (Página 129)\n",
      "  Nivel 2: Postings file compression (Página 132)\n",
      "    Nivel 3: Variable byte codes (Página 133)\n",
      "    Nivel 3: Gamma codes (Página 135)\n",
      "  Nivel 2: References and further reading (Página 142)\n",
      "Nivel 1: Scoring, term weighting and the vector space model (Página 146)\n",
      "  Nivel 2: Parametric and zone indexes (Página 147)\n",
      "    Nivel 3: Weighted zone scoring (Página 149)\n",
      "    Nivel 3: Learning weights (Página 150)\n",
      "    Nivel 3: The optimal weight g (Página 152)\n",
      "  Nivel 2: Term frequency and weighting (Página 154)\n",
      "    Nivel 3: Inverse document frequency (Página 154)\n",
      "    Nivel 3: Tf-idf weighting (Página 155)\n",
      "  Nivel 2: The vector space model for scoring (Página 157)\n",
      "    Nivel 3: Dot products (Página 157)\n",
      "    Nivel 3: Queries as vectors (Página 160)\n",
      "    Nivel 3: Computing vector scores (Página 161)\n",
      "  Nivel 2: Variant tf-idf functions (Página 163)\n",
      "    Nivel 3: Sublinear tf scaling (Página 163)\n",
      "    Nivel 3: Maximum tf normalization (Página 164)\n",
      "    Nivel 3: Document and query weighting schemes (Página 165)\n",
      "    Nivel 3: Pivoted normalized document length (Página 166)\n",
      "  Nivel 2: References and further reading (Página 170)\n",
      "Nivel 1: Computing scores in a complete search system (Página 172)\n",
      "  Nivel 2: Efficient scoring and ranking (Página 172)\n",
      "    Nivel 3: Inexact top K document retrieval (Página 174)\n",
      "    Nivel 3: Index elimination (Página 174)\n",
      "    Nivel 3: Champion lists (Página 175)\n",
      "    Nivel 3: Static quality scores and ordering (Página 175)\n",
      "    Nivel 3: Impact ordering (Página 177)\n",
      "    Nivel 3: Cluster pruning (Página 178)\n",
      "  Nivel 2: Components of an information retrieval system (Página 180)\n",
      "    Nivel 3: Tiered indexes (Página 180)\n",
      "    Nivel 3: Query-term proximity (Página 181)\n",
      "    Nivel 3: Designing parsing and scoring functions (Página 182)\n",
      "    Nivel 3: Putting it all together (Página 183)\n",
      "  Nivel 2: Vector space scoring and query operator interaction (Página 184)\n",
      "  Nivel 2: References and further reading (Página 186)\n",
      "Nivel 1: Evaluation in information retrieval (Página 188)\n",
      "  Nivel 2: Information retrieval system evaluation (Página 189)\n",
      "  Nivel 2: Standard test collections (Página 190)\n",
      "  Nivel 2: Evaluation of unranked retrieval sets (Página 191)\n",
      "  Nivel 2: Evaluation of ranked retrieval results (Página 195)\n",
      "  Nivel 2: Assessing relevance (Página 201)\n",
      "    Nivel 3: Critiques and justifications of the concept of relevance (Página 203)\n",
      "  Nivel 2: A broader perspective: System quality and user utility (Página 205)\n",
      "    Nivel 3: System issues (Página 205)\n",
      "    Nivel 3: User utility (Página 206)\n"
     ]
    }
   ],
   "source": [
    "# Verificar si el PDF tiene tabla de contenidos (TOC)\n",
    "toc = doc.get_toc()\n",
    "\n",
    "if toc:\n",
    "    print(f\"¡El PDF tiene {len(toc)} elementos en la tabla de contenidos!\")\n",
    "    print(\"\\nPrimeras 10 entradas:\")\n",
    "    for i, (level, title, page) in enumerate(toc[:100]):\n",
    "        indent = \"  \" * (level - 1)\n",
    "        print(f\"{indent}Nivel {level}: {title} (Página {page})\")\n",
    "else:\n",
    "    print(\"El PDF no tiene tabla de contenidos estructurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17142bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se extrajeron 252 documentos desde la página 38\n",
      "\n",
      "Primeros 10 documentos:\n",
      "   doc_id  level                                              title  \\\n",
      "0       1      1                                  Boolean retrieval   \n",
      "1       2      2           An example information retrieval problem   \n",
      "2       3      2         A first take at building an inverted index   \n",
      "3       4      2                         Processing Boolean queries   \n",
      "4       5      2  The extended Boolean model versus ranked retri...   \n",
      "5       6      2                     References and further reading   \n",
      "6       7      1             The term vocabulary and postings lists   \n",
      "7       8      2  Document delineation and character sequence de...   \n",
      "8       9      3     Obtaining the character sequence in a document   \n",
      "9      10      3                           Choosing a document unit   \n",
      "\n",
      "   start_page  end_page  word_count  \n",
      "0          38        39         869  \n",
      "1          40        42        1276  \n",
      "2          43        46        1732  \n",
      "3          47        50        1402  \n",
      "4          51        53        1387  \n",
      "5          54        55         523  \n",
      "6          56        55           0  \n",
      "7          56        55           0  \n",
      "8          56        56         284  \n",
      "9          57        58         973  \n"
     ]
    }
   ],
   "source": [
    "def extract_hierarchical_documents(doc, start_page=38):\n",
    "    \"\"\"\n",
    "    Extrae documentos jerárquicos desde una página específica\n",
    "    Cada elemento de TOC se convierte en un documento separado\n",
    "    \"\"\"\n",
    "    toc = doc.get_toc()\n",
    "    \n",
    "    if not toc:\n",
    "        print(\"No hay tabla de contenidos disponible\")\n",
    "        return None\n",
    "    \n",
    "    # Filtrar TOC desde la página especificada\n",
    "    filtered_toc = [(level, title, page) for level, title, page in toc if page >= start_page]\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for i, (level, title, start_page_toc) in enumerate(filtered_toc):\n",
    "        # Determinar página final del documento\n",
    "        if i + 1 < len(filtered_toc):\n",
    "            end_page = filtered_toc[i + 1][2] - 1\n",
    "        else:\n",
    "            end_page = len(doc)\n",
    "        \n",
    "        # Extraer texto del rango de páginas\n",
    "        content = \"\"\n",
    "        for page_num in range(start_page_toc - 1, min(end_page, len(doc))):\n",
    "            if page_num < len(doc):\n",
    "                page_text = doc[page_num].get_text()\n",
    "                content += page_text + \"\\n\"\n",
    "        \n",
    "        documents.append({\n",
    "            'doc_id': i + 1,\n",
    "            'level': level,\n",
    "            'title': title.strip(),\n",
    "            'start_page': start_page_toc,\n",
    "            'end_page': end_page,\n",
    "            'content': content.strip(),\n",
    "            'word_count': len(content.split()),\n",
    "            'char_count': len(content),\n",
    "            'parent_level': level - 1 if level > 1 else None\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(documents)\n",
    "\n",
    "# Extraer documentos jerárquicos desde página 38\n",
    "hierarchical_docs_df = extract_hierarchical_documents(doc, start_page=38)\n",
    "\n",
    "if hierarchical_docs_df is not None:\n",
    "    print(f\"Se extrajeron {len(hierarchical_docs_df)} documentos desde la página 38\")\n",
    "    print(\"\\nPrimeros 10 documentos:\")\n",
    "    print(hierarchical_docs_df[['doc_id', 'level', 'title', 'start_page', 'end_page', 'word_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f33b69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>parent_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Boolean retrieval</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...</td>\n",
       "      <td>869</td>\n",
       "      <td>5449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>An example information retrieval problem</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n1.1\\nAn...</td>\n",
       "      <td>1276</td>\n",
       "      <td>7296</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>A first take at building an inverted index</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n6\\n1\\nB...</td>\n",
       "      <td>1732</td>\n",
       "      <td>9452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Processing Boolean queries</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n10\\n1\\n...</td>\n",
       "      <td>1402</td>\n",
       "      <td>8273</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>The extended Boolean model versus ranked retri...</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n14\\n1\\n...</td>\n",
       "      <td>1387</td>\n",
       "      <td>8516</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>2</td>\n",
       "      <td>Hubs and Authorities</td>\n",
       "      <td>511</td>\n",
       "      <td>513</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n474\\n21...</td>\n",
       "      <td>1261</td>\n",
       "      <td>7061</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>Choosing the subset of the Web</td>\n",
       "      <td>514</td>\n",
       "      <td>516</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n21.3\\nH...</td>\n",
       "      <td>1066</td>\n",
       "      <td>5945</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>References and further reading</td>\n",
       "      <td>517</td>\n",
       "      <td>519</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n480\\n21...</td>\n",
       "      <td>628</td>\n",
       "      <td>3784</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>Bibliography</td>\n",
       "      <td>520</td>\n",
       "      <td>557</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...</td>\n",
       "      <td>14866</td>\n",
       "      <td>105679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>Author Index</td>\n",
       "      <td>558</td>\n",
       "      <td>581</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nAuthor ...</td>\n",
       "      <td>8240</td>\n",
       "      <td>53513</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id  level                                              title  \\\n",
       "0         1      1                                  Boolean retrieval   \n",
       "1         2      2           An example information retrieval problem   \n",
       "2         3      2         A first take at building an inverted index   \n",
       "3         4      2                         Processing Boolean queries   \n",
       "4         5      2  The extended Boolean model versus ranked retri...   \n",
       "..      ...    ...                                                ...   \n",
       "247     248      2                               Hubs and Authorities   \n",
       "248     249      3                     Choosing the subset of the Web   \n",
       "249     250      2                     References and further reading   \n",
       "250     251      1                                       Bibliography   \n",
       "251     252      1                                       Author Index   \n",
       "\n",
       "     start_page  end_page                                            content  \\\n",
       "0            38        39  Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...   \n",
       "1            40        42  Online edition (c)\\n2009 Cambridge UP\\n1.1\\nAn...   \n",
       "2            43        46  Online edition (c)\\n2009 Cambridge UP\\n6\\n1\\nB...   \n",
       "3            47        50  Online edition (c)\\n2009 Cambridge UP\\n10\\n1\\n...   \n",
       "4            51        53  Online edition (c)\\n2009 Cambridge UP\\n14\\n1\\n...   \n",
       "..          ...       ...                                                ...   \n",
       "247         511       513  Online edition (c)\\n2009 Cambridge UP\\n474\\n21...   \n",
       "248         514       516  Online edition (c)\\n2009 Cambridge UP\\n21.3\\nH...   \n",
       "249         517       519  Online edition (c)\\n2009 Cambridge UP\\n480\\n21...   \n",
       "250         520       557  Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...   \n",
       "251         558       581  Online edition (c)\\n2009 Cambridge UP\\nAuthor ...   \n",
       "\n",
       "     word_count  char_count  parent_level  \n",
       "0           869        5449           NaN  \n",
       "1          1276        7296           1.0  \n",
       "2          1732        9452           1.0  \n",
       "3          1402        8273           1.0  \n",
       "4          1387        8516           1.0  \n",
       "..          ...         ...           ...  \n",
       "247        1261        7061           1.0  \n",
       "248        1066        5945           2.0  \n",
       "249         628        3784           1.0  \n",
       "250       14866      105679           NaN  \n",
       "251        8240       53513           NaN  \n",
       "\n",
       "[252 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6c9c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\roble\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\roble\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297c5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_docs(docs):\n",
    "    # Primero, vamos a ver qué contiene realmente el texto\n",
    "    # print(f\"Texto original (primeros 200 chars): {repr(docs[:200])}\")\n",
    "    \n",
    "    # Lista de textos específicos a eliminar con diferentes variaciones\n",
    "    unwanted_texts = [\n",
    "        \"b'Online edition (c)\\\\n2009 Cambridge UP\\\\n\",\n",
    "        \"b'Online edition (c)\\\\\\\\n2009 Cambridge UP\\\\\\\\n\",\n",
    "        \"Online edition (c) 2009 Cambridge UP\",\n",
    "        \"Online edition (c)\\\\n2009 Cambridge UP\",\n",
    "        \"Cambridge University Press\",\n",
    "        \"All rights reserved\",\n",
    "        \"2009 Cambridge UP\",\n",
    "    ]\n",
    "    \n",
    "    # Eliminar textos específicos\n",
    "    for unwanted in unwanted_texts:\n",
    "        docs = docs.replace(unwanted, \"\")\n",
    "    \n",
    "    # Usar regex para patrones más flexibles\n",
    "    patterns_to_remove = [\n",
    "        r\"b'Online edition.*?Cambridge UP.*?'\",\n",
    "        r\"Online edition.*?Cambridge UP\",\n",
    "        r\"Cambridge University Press\",\n",
    "        r\"All rights reserved\",\n",
    "        r\"2009 Cambridge UP\",\n",
    "        r\"\\\\\\\\x[0-9a-fA-F]{2}\",  # Caracteres hexadecimales con doble escape\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns_to_remove:\n",
    "        docs = re.sub(pattern, \"\", docs, flags=re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # Limpiar caracteres de escape y formateo\n",
    "    docs = re.sub(r\"b'\", \"\", docs)  # Eliminar b'\n",
    "    docs = re.sub(r\"'\", \"\", docs)   # Eliminar comillas finales\n",
    "    docs = re.sub(r\"\\\\\\\\n\", \" \", docs)  # Doble escape de saltos de línea\n",
    "    docs = re.sub(r\"\\\\n\", \" \", docs)  # Saltos de línea simples\n",
    "    docs = re.sub(r\"\\\\\\\\t\", \" \", docs)  # Doble escape de tabs\n",
    "    docs = re.sub(r\"\\\\t\", \" \", docs)  # Tabs simples\n",
    "    docs = re.sub(r\"\\\\\\\\x\\w{2}\", \"\", docs)  # Caracteres hexadecimales con doble escape\n",
    "    docs = re.sub(r\"\\\\x\\w{2}\", \"\", docs)  # Caracteres hexadecimales simples\n",
    "    \n",
    "    # Eliminar números de página aislados\n",
    "    docs = re.sub(r'\\b\\d{1,3}\\b', '', docs)\n",
    "    \n",
    "    # Eliminar caracteres especiales excesivos\n",
    "    docs = re.sub(r'[^\\w\\s]', ' ', docs)\n",
    "    \n",
    "    # Limpiar espacios múltiples\n",
    "    docs = re.sub(r'\\s+', ' ', docs).strip()\n",
    "    \n",
    "    # Tokenizar y filtrar\n",
    "    words = word_tokenize(docs)\n",
    "    word_filtered = [w for w in words if w not in stop_words and w.isalpha() and len(w) > 2]\n",
    "    return ' '.join(word_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1869e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_docs_aggressive(docs):\n",
    "    \"\"\"Versión más agresiva de limpieza\"\"\"\n",
    "    \n",
    "    # Convertir a string si no lo es\n",
    "    docs = str(docs)\n",
    "    \n",
    "    # Eliminar todo lo que empiece con \"b'\" y termine con una comilla\n",
    "    docs = re.sub(r\"b'.*?'\", \"\", docs, flags=re.DOTALL)\n",
    "    \n",
    "    # Eliminar todas las menciones de Cambridge UP y related\n",
    "    cambridge_patterns = [\n",
    "        r\".*Cambridge.*UP.*\",\n",
    "        r\".*Online edition.*\",\n",
    "        r\".*All rights reserved.*\",\n",
    "        r\".*2009.*Cambridge.*\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in cambridge_patterns:\n",
    "        docs = re.sub(pattern, \"\", docs, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Limpiar todos los tipos de escape\n",
    "    escape_patterns = [\n",
    "        r\"\\\\\\\\n\", r\"\\\\n\",      # Saltos de línea\n",
    "        r\"\\\\\\\\t\", r\"\\\\t\",      # Tabulaciones  \n",
    "        r\"\\\\\\\\x[0-9a-fA-F]{2}\", r\"\\\\x[0-9a-fA-F]{2}\",  # Hex\n",
    "        r\"\\\\\\\\\", r\"\\\\\"         # Backslashes\n",
    "    ]\n",
    "    \n",
    "    for pattern in escape_patterns:\n",
    "        docs = re.sub(pattern, \" \", docs)\n",
    "    \n",
    "    # Eliminar números aislados (páginas)\n",
    "    docs = re.sub(r'\\b\\d{1,3}\\b', '', docs)\n",
    "    \n",
    "    # Limpiar caracteres especiales\n",
    "    docs = re.sub(r'[^\\w\\s]', ' ', docs)\n",
    "    \n",
    "    # Limpiar espacios múltiples\n",
    "    docs = re.sub(r'\\s+', ' ', docs).strip()\n",
    "    \n",
    "    # Tokenizar y filtrar\n",
    "    words = word_tokenize(docs)\n",
    "    word_filtered = [w for w in words if w not in stop_words and w.isalpha() and len(w) > 2]\n",
    "    return ' '.join(word_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73085987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando preprocesamiento mejorado...\n",
      "Antes del preprocesamiento:\n",
      "'Online edition (c)\\n2009 Cambridge UP\\nDRAFT! © April 1, 2009 Cambridge University Press. Feedback welcome.\\n1\\n1\\nBoolean retrieval\\nThe meaning of the term information retrieval can be very broad. Just ge'\n",
      "\n",
      "Después del preprocesamiento:\n",
      "Boolean retrieval The meaning term information retrieval broad Just getting credit card wallet type card number form information retrieval However academic ﬁeld study information retrieval might deﬁne\n",
      "\n",
      "Documentos finales después del preprocesamiento: 215\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la nueva función de preprocesamiento\n",
    "if hierarchical_docs_df is not None:\n",
    "    print(\"Aplicando preprocesamiento mejorado...\")\n",
    "    \n",
    "    # Probar con el primer documento para ver si funciona\n",
    "    test_doc = hierarchical_docs_df.iloc[0]['content']\n",
    "    print(\"Antes del preprocesamiento:\")\n",
    "    print(repr(test_doc[:200]))\n",
    "    \n",
    "    cleaned_test = preprocess_docs_aggressive(test_doc)\n",
    "    print(\"\\nDespués del preprocesamiento:\")\n",
    "    print(cleaned_test[:200])\n",
    "    \n",
    "    # Aplicar a todos los documentos\n",
    "    hierarchical_docs_df['preprocessed'] = hierarchical_docs_df['content'].apply(preprocess_docs_aggressive)\n",
    "    \n",
    "    # Filtrar documentos con contenido válido\n",
    "    hierarchical_docs_df = hierarchical_docs_df[hierarchical_docs_df['preprocessed'].str.len() > 50]\n",
    "    \n",
    "    print(f\"\\nDocumentos finales después del preprocesamiento: {len(hierarchical_docs_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82651c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>parent_level</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Boolean retrieval</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...</td>\n",
       "      <td>869</td>\n",
       "      <td>5449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boolean retrieval The meaning term information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>An example information retrieval problem</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n1.1\\nAn...</td>\n",
       "      <td>1276</td>\n",
       "      <td>7296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>example information retrieval problem chapter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>A first take at building an inverted index</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n6\\n1\\nB...</td>\n",
       "      <td>1732</td>\n",
       "      <td>9452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boolean retrieval Detailed discussion relevanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Processing Boolean queries</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n10\\n1\\n...</td>\n",
       "      <td>1402</td>\n",
       "      <td>8273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boolean retrieval Brutus Calpurnia Intersectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>The extended Boolean model versus ranked retri...</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n14\\n1\\n...</td>\n",
       "      <td>1387</td>\n",
       "      <td>8516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boolean retrieval Term Postings size eyes kale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>2</td>\n",
       "      <td>Hubs and Authorities</td>\n",
       "      <td>511</td>\n",
       "      <td>513</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n474\\n21...</td>\n",
       "      <td>1261</td>\n",
       "      <td>7061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Link analysis Exercise Suppose web graph store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>Choosing the subset of the Web</td>\n",
       "      <td>514</td>\n",
       "      <td>516</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n21.3\\nH...</td>\n",
       "      <td>1066</td>\n",
       "      <td>5945</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hubs Authorities Output top scoring hubs top s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>References and further reading</td>\n",
       "      <td>517</td>\n",
       "      <td>519</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n480\\n21...</td>\n",
       "      <td>628</td>\n",
       "      <td>3784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Link analysis Exercise How would interpret ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>Bibliography</td>\n",
       "      <td>520</td>\n",
       "      <td>557</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...</td>\n",
       "      <td>14866</td>\n",
       "      <td>105679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bibliography use following abbreviated journal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>Author Index</td>\n",
       "      <td>558</td>\n",
       "      <td>581</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nAuthor ...</td>\n",
       "      <td>8240</td>\n",
       "      <td>53513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author Index Aberer Aberer Ahn Ittner Aizerman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id  level                                              title  \\\n",
       "0         1      1                                  Boolean retrieval   \n",
       "1         2      2           An example information retrieval problem   \n",
       "2         3      2         A first take at building an inverted index   \n",
       "3         4      2                         Processing Boolean queries   \n",
       "4         5      2  The extended Boolean model versus ranked retri...   \n",
       "..      ...    ...                                                ...   \n",
       "247     248      2                               Hubs and Authorities   \n",
       "248     249      3                     Choosing the subset of the Web   \n",
       "249     250      2                     References and further reading   \n",
       "250     251      1                                       Bibliography   \n",
       "251     252      1                                       Author Index   \n",
       "\n",
       "     start_page  end_page                                            content  \\\n",
       "0            38        39  Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...   \n",
       "1            40        42  Online edition (c)\\n2009 Cambridge UP\\n1.1\\nAn...   \n",
       "2            43        46  Online edition (c)\\n2009 Cambridge UP\\n6\\n1\\nB...   \n",
       "3            47        50  Online edition (c)\\n2009 Cambridge UP\\n10\\n1\\n...   \n",
       "4            51        53  Online edition (c)\\n2009 Cambridge UP\\n14\\n1\\n...   \n",
       "..          ...       ...                                                ...   \n",
       "247         511       513  Online edition (c)\\n2009 Cambridge UP\\n474\\n21...   \n",
       "248         514       516  Online edition (c)\\n2009 Cambridge UP\\n21.3\\nH...   \n",
       "249         517       519  Online edition (c)\\n2009 Cambridge UP\\n480\\n21...   \n",
       "250         520       557  Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...   \n",
       "251         558       581  Online edition (c)\\n2009 Cambridge UP\\nAuthor ...   \n",
       "\n",
       "     word_count  char_count  parent_level  \\\n",
       "0           869        5449           NaN   \n",
       "1          1276        7296           1.0   \n",
       "2          1732        9452           1.0   \n",
       "3          1402        8273           1.0   \n",
       "4          1387        8516           1.0   \n",
       "..          ...         ...           ...   \n",
       "247        1261        7061           1.0   \n",
       "248        1066        5945           2.0   \n",
       "249         628        3784           1.0   \n",
       "250       14866      105679           NaN   \n",
       "251        8240       53513           NaN   \n",
       "\n",
       "                                          preprocessed  \n",
       "0    Boolean retrieval The meaning term information...  \n",
       "1    example information retrieval problem chapter ...  \n",
       "2    Boolean retrieval Detailed discussion relevanc...  \n",
       "3    Boolean retrieval Brutus Calpurnia Intersectio...  \n",
       "4    Boolean retrieval Term Postings size eyes kale...  \n",
       "..                                                 ...  \n",
       "247  Link analysis Exercise Suppose web graph store...  \n",
       "248  Hubs Authorities Output top scoring hubs top s...  \n",
       "249  Link analysis Exercise How would interpret ent...  \n",
       "250  Bibliography use following abbreviated journal...  \n",
       "251  Author Index Aberer Aberer Ahn Ittner Aizerman...  \n",
       "\n",
       "[215 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4328be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ec8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af7aa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(hierarchical_docs_df['preprocessed'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06beaf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00876109, -0.01737127, -0.04260701, ..., -0.03232197,\n",
       "         0.01516353, -0.02024754],\n",
       "       [ 0.01462434,  0.01935861, -0.03255737, ..., -0.00875811,\n",
       "         0.00207664,  0.02770639],\n",
       "       [-0.00840228, -0.03102122, -0.04935666, ...,  0.00183343,\n",
       "        -0.00840126,  0.02426352],\n",
       "       ...,\n",
       "       [-0.00951959, -0.05244111, -0.09500014, ...,  0.01779133,\n",
       "        -0.04317988, -0.01395471],\n",
       "       [-0.03801242, -0.06153281, -0.05434936, ..., -0.04515737,\n",
       "        -0.0508875 , -0.01516703],\n",
       "       [ 0.04286065, -0.05765121, -0.03717588, ..., -0.00721208,\n",
       "         0.0131214 , -0.04086863]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca828f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roble\\AppData\\Local\\Temp\\ipykernel_23960\\3100931681.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hierarchical_docs_df['embedding'] = list(embeddings[:1000])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>parent_level</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Boolean retrieval</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...</td>\n",
       "      <td>869</td>\n",
       "      <td>5449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boolean retrieval The meaning term information...</td>\n",
       "      <td>[0.008761087, -0.01737127, -0.042607006, 0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>An example information retrieval problem</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n1.1\\nAn...</td>\n",
       "      <td>1276</td>\n",
       "      <td>7296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>example information retrieval problem chapter ...</td>\n",
       "      <td>[0.014624343, 0.01935861, -0.03255737, -0.0307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>A first take at building an inverted index</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n6\\n1\\nB...</td>\n",
       "      <td>1732</td>\n",
       "      <td>9452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boolean retrieval Detailed discussion relevanc...</td>\n",
       "      <td>[-0.008402278, -0.031021217, -0.049356658, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Processing Boolean queries</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n10\\n1\\n...</td>\n",
       "      <td>1402</td>\n",
       "      <td>8273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boolean retrieval Brutus Calpurnia Intersectio...</td>\n",
       "      <td>[-0.020248102, -0.038778815, -0.07978982, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>The extended Boolean model versus ranked retri...</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n14\\n1\\n...</td>\n",
       "      <td>1387</td>\n",
       "      <td>8516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boolean retrieval Term Postings size eyes kale...</td>\n",
       "      <td>[0.032437306, -0.03302262, -0.023949256, 0.046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>2</td>\n",
       "      <td>Hubs and Authorities</td>\n",
       "      <td>511</td>\n",
       "      <td>513</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n474\\n21...</td>\n",
       "      <td>1261</td>\n",
       "      <td>7061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Link analysis Exercise Suppose web graph store...</td>\n",
       "      <td>[0.02554892, -0.024918225, -0.06523086, -0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>Choosing the subset of the Web</td>\n",
       "      <td>514</td>\n",
       "      <td>516</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n21.3\\nH...</td>\n",
       "      <td>1066</td>\n",
       "      <td>5945</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hubs Authorities Output top scoring hubs top s...</td>\n",
       "      <td>[0.025388028, -0.03269337, -0.059302106, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>References and further reading</td>\n",
       "      <td>517</td>\n",
       "      <td>519</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\n480\\n21...</td>\n",
       "      <td>628</td>\n",
       "      <td>3784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Link analysis Exercise How would interpret ent...</td>\n",
       "      <td>[-0.009519593, -0.05244111, -0.09500014, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>Bibliography</td>\n",
       "      <td>520</td>\n",
       "      <td>557</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...</td>\n",
       "      <td>14866</td>\n",
       "      <td>105679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bibliography use following abbreviated journal...</td>\n",
       "      <td>[-0.038012423, -0.061532807, -0.05434936, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>Author Index</td>\n",
       "      <td>558</td>\n",
       "      <td>581</td>\n",
       "      <td>Online edition (c)\\n2009 Cambridge UP\\nAuthor ...</td>\n",
       "      <td>8240</td>\n",
       "      <td>53513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author Index Aberer Aberer Ahn Ittner Aizerman...</td>\n",
       "      <td>[0.04286065, -0.05765121, -0.03717588, 0.00805...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id  level                                              title  \\\n",
       "0         1      1                                  Boolean retrieval   \n",
       "1         2      2           An example information retrieval problem   \n",
       "2         3      2         A first take at building an inverted index   \n",
       "3         4      2                         Processing Boolean queries   \n",
       "4         5      2  The extended Boolean model versus ranked retri...   \n",
       "..      ...    ...                                                ...   \n",
       "247     248      2                               Hubs and Authorities   \n",
       "248     249      3                     Choosing the subset of the Web   \n",
       "249     250      2                     References and further reading   \n",
       "250     251      1                                       Bibliography   \n",
       "251     252      1                                       Author Index   \n",
       "\n",
       "     start_page  end_page                                            content  \\\n",
       "0            38        39  Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...   \n",
       "1            40        42  Online edition (c)\\n2009 Cambridge UP\\n1.1\\nAn...   \n",
       "2            43        46  Online edition (c)\\n2009 Cambridge UP\\n6\\n1\\nB...   \n",
       "3            47        50  Online edition (c)\\n2009 Cambridge UP\\n10\\n1\\n...   \n",
       "4            51        53  Online edition (c)\\n2009 Cambridge UP\\n14\\n1\\n...   \n",
       "..          ...       ...                                                ...   \n",
       "247         511       513  Online edition (c)\\n2009 Cambridge UP\\n474\\n21...   \n",
       "248         514       516  Online edition (c)\\n2009 Cambridge UP\\n21.3\\nH...   \n",
       "249         517       519  Online edition (c)\\n2009 Cambridge UP\\n480\\n21...   \n",
       "250         520       557  Online edition (c)\\n2009 Cambridge UP\\nDRAFT! ...   \n",
       "251         558       581  Online edition (c)\\n2009 Cambridge UP\\nAuthor ...   \n",
       "\n",
       "     word_count  char_count  parent_level  \\\n",
       "0           869        5449           NaN   \n",
       "1          1276        7296           1.0   \n",
       "2          1732        9452           1.0   \n",
       "3          1402        8273           1.0   \n",
       "4          1387        8516           1.0   \n",
       "..          ...         ...           ...   \n",
       "247        1261        7061           1.0   \n",
       "248        1066        5945           2.0   \n",
       "249         628        3784           1.0   \n",
       "250       14866      105679           NaN   \n",
       "251        8240       53513           NaN   \n",
       "\n",
       "                                          preprocessed  \\\n",
       "0    Boolean retrieval The meaning term information...   \n",
       "1    example information retrieval problem chapter ...   \n",
       "2    Boolean retrieval Detailed discussion relevanc...   \n",
       "3    Boolean retrieval Brutus Calpurnia Intersectio...   \n",
       "4    Boolean retrieval Term Postings size eyes kale...   \n",
       "..                                                 ...   \n",
       "247  Link analysis Exercise Suppose web graph store...   \n",
       "248  Hubs Authorities Output top scoring hubs top s...   \n",
       "249  Link analysis Exercise How would interpret ent...   \n",
       "250  Bibliography use following abbreviated journal...   \n",
       "251  Author Index Aberer Aberer Ahn Ittner Aizerman...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.008761087, -0.01737127, -0.042607006, 0.022...  \n",
       "1    [0.014624343, 0.01935861, -0.03255737, -0.0307...  \n",
       "2    [-0.008402278, -0.031021217, -0.049356658, 0.0...  \n",
       "3    [-0.020248102, -0.038778815, -0.07978982, 0.01...  \n",
       "4    [0.032437306, -0.03302262, -0.023949256, 0.046...  \n",
       "..                                                 ...  \n",
       "247  [0.02554892, -0.024918225, -0.06523086, -0.009...  \n",
       "248  [0.025388028, -0.03269337, -0.059302106, -0.01...  \n",
       "249  [-0.009519593, -0.05244111, -0.09500014, -0.03...  \n",
       "250  [-0.038012423, -0.061532807, -0.05434936, 0.02...  \n",
       "251  [0.04286065, -0.05765121, -0.03717588, 0.00805...  \n",
       "\n",
       "[215 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_docs_df['embedding'] = list(embeddings[:1000])\n",
    "hierarchical_docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b8fff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2807815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56612131e-02 -1.75286066e-02 -4.20964509e-02 -4.82783746e-03\n",
      "  7.46160513e-03 -4.96165156e-02  2.50388943e-02  1.12307603e-02\n",
      " -5.43479212e-02 -1.36764301e-02 -1.60393212e-02 -6.74523115e-02\n",
      "  5.85131394e-03 -2.74366476e-02 -4.30077128e-02 -5.87044060e-02\n",
      "  1.35599896e-01  8.07881262e-03 -5.46144135e-02 -1.17088497e-01\n",
      " -8.14201981e-02 -9.00198519e-02  3.49609964e-02 -2.93366350e-02\n",
      "  1.47342965e-01  8.41984618e-03 -4.04698066e-02  6.24017008e-02\n",
      "  3.69590730e-03 -6.01331554e-02  3.09085324e-02 -1.41630759e-02\n",
      "  3.47727649e-02  7.90730584e-03 -5.61596341e-02 -3.24862003e-02\n",
      " -3.14878160e-03 -3.45449522e-02  8.17072466e-02  1.95760708e-02\n",
      " -2.75278371e-02 -1.09901866e-02  5.54863364e-02  2.31004152e-02\n",
      "  5.48508726e-02  1.78303197e-02 -6.53773360e-03 -6.62332680e-03\n",
      " -5.36817499e-02 -5.86747564e-03 -1.19842485e-01  3.91858630e-03\n",
      " -1.03120841e-02 -1.57604143e-02 -1.82269942e-02  7.70807713e-02\n",
      "  4.85998280e-02 -6.73391372e-02  3.68102565e-02 -1.14895124e-02\n",
      "  9.18866470e-02 -1.17844045e-01 -6.60137311e-02  3.38423513e-02\n",
      "  1.46033511e-01 -2.20243409e-02  6.11934774e-02 -4.97914851e-02\n",
      "  3.20269726e-02 -7.00151606e-04 -6.93188012e-02  6.38001859e-02\n",
      "  1.02599123e-02  4.12175320e-02  6.07949588e-03 -5.90201188e-03\n",
      " -1.16444763e-03 -1.13039846e-02  8.71661957e-03 -1.33275062e-01\n",
      "  5.53129101e-03 -8.73018652e-02 -9.35543701e-02  2.66725644e-02\n",
      "  8.26821625e-02 -1.49097955e-02  8.87324214e-02  6.38990104e-02\n",
      "  1.84347853e-02 -2.18634941e-02 -3.00917029e-03  3.81090753e-02\n",
      " -3.68951336e-02 -8.62746127e-03 -2.82615088e-02  5.19292355e-02\n",
      "  9.20185596e-02 -2.03262288e-02  6.33690142e-05  1.86078548e-01\n",
      "  4.44482267e-03 -1.20864613e-02 -1.50666926e-02  9.52102337e-03\n",
      "  4.59172241e-02 -2.22868267e-02  8.62888172e-02  2.78845504e-02\n",
      "  1.70383491e-02 -3.88606191e-02  3.68393846e-02 -2.66514365e-02\n",
      " -3.57825086e-02 -5.63999917e-03  5.06904088e-02 -6.97164536e-02\n",
      " -7.55214039e-03 -3.21811973e-03  3.66915315e-02 -6.58284267e-03\n",
      "  1.88757002e-03 -3.74398865e-02  1.86479911e-02  1.66337099e-02\n",
      " -1.98154096e-02  5.49874343e-02  7.67898094e-03 -7.98041737e-34\n",
      " -1.31995203e-02  1.75464675e-02  3.16644683e-02 -4.45479490e-02\n",
      " -2.05744114e-02 -4.92373258e-02 -5.72683364e-02 -2.49442719e-02\n",
      " -4.26514447e-02  5.16091101e-02 -5.27993329e-02 -2.57296283e-02\n",
      " -4.36349250e-02  2.92710587e-02  7.25514293e-02 -1.74963369e-03\n",
      "  5.34922758e-04  6.34413734e-02 -4.44015339e-02  4.56145108e-02\n",
      "  4.03334051e-02 -2.70465575e-02 -7.69957481e-03 -6.97673261e-02\n",
      "  4.12023775e-02  1.69309769e-02  6.71190908e-03 -2.24932786e-02\n",
      " -2.94390321e-02  3.19827832e-02  1.26584908e-02 -3.50014381e-02\n",
      " -5.04815467e-02  1.57535803e-02  6.76274896e-02 -3.47425267e-02\n",
      " -1.79653391e-02 -1.94674060e-02 -2.38813972e-03 -2.03442145e-02\n",
      " -8.62451717e-02  2.39749011e-02 -1.58324819e-02 -4.89598177e-02\n",
      " -4.56054471e-02 -3.38874906e-02 -6.87026531e-02  1.08420495e-02\n",
      "  9.08092596e-03  2.11189222e-03 -3.20167979e-03  5.00720926e-02\n",
      " -7.42275044e-02 -2.75009144e-02  5.05591258e-02 -2.41336878e-02\n",
      "  4.48614918e-02  1.98590681e-02  4.34278101e-02  1.77440971e-01\n",
      "  6.76060654e-03  4.52805050e-02 -7.72174224e-02 -8.38175602e-03\n",
      " -9.17668864e-02  1.60119087e-02 -7.87437707e-02  4.12958637e-02\n",
      "  6.40497282e-02  3.53396609e-02 -2.33292226e-02 -1.19092949e-02\n",
      "  3.85727063e-02 -7.08945021e-02  9.56705138e-02  1.51121954e-03\n",
      "  1.20789297e-02 -7.98411388e-03 -8.96167234e-02 -5.71459755e-02\n",
      " -9.52659622e-02  9.57439542e-02 -2.29517929e-02 -7.84819294e-03\n",
      " -3.61203775e-02 -5.21306060e-02 -2.67133359e-02 -4.50270809e-02\n",
      " -5.71186692e-02  1.83250196e-02 -9.10718739e-02  2.39364970e-02\n",
      " -2.42465157e-02 -5.37834270e-03  9.07502428e-04  1.59079136e-33\n",
      " -7.40717864e-03 -2.34123436e-03  3.44713219e-02  1.51158974e-01\n",
      "  2.85086613e-02 -3.16912793e-02 -4.69973013e-02  3.56685035e-02\n",
      " -3.89323719e-02  6.75591454e-02  2.90642902e-02  1.41245974e-02\n",
      "  3.62315699e-02 -2.97228852e-03  2.68303882e-02  2.66999044e-02\n",
      " -1.60793513e-02 -7.61324987e-02 -1.33591536e-02 -1.22723868e-02\n",
      "  8.77476297e-03  2.15643458e-02  1.93034075e-02  7.52580352e-03\n",
      " -6.67227730e-02  5.70997894e-02 -9.14305001e-02 -6.19000420e-02\n",
      " -5.58989644e-02 -1.54054135e-01  1.23079615e-02 -1.55382445e-02\n",
      " -4.01477031e-02  8.83569662e-03 -3.14148031e-02  7.15323910e-02\n",
      "  8.70910212e-02  3.19856368e-02  8.64233449e-03  5.13594337e-02\n",
      "  6.47421405e-02  3.92852761e-02 -3.88381742e-02 -3.16691324e-02\n",
      "  3.13229300e-02  5.14333360e-02 -7.44104013e-02  5.62802404e-02\n",
      "  3.94993648e-02  4.89951819e-02  2.81459801e-02  2.18672380e-02\n",
      " -2.54736897e-02  1.86088998e-02  6.02585040e-02 -6.57797828e-02\n",
      " -1.27201065e-01 -3.51070538e-02  2.85975561e-02  3.06087509e-02\n",
      " -1.15469638e-02 -4.63192537e-03 -1.00317344e-01  1.55149072e-01\n",
      " -2.95409672e-02 -1.58080328e-02 -9.54686571e-03 -3.81892733e-02\n",
      "  8.89093056e-03  8.82626176e-02  1.16165970e-02 -5.41175948e-03\n",
      " -4.10159864e-02  6.99271187e-02 -2.44599581e-02 -1.10732960e-02\n",
      "  7.06694601e-03  5.56474887e-02 -2.08877400e-03  6.95824325e-02\n",
      "  4.58715251e-03 -2.34323628e-02 -9.25098639e-03  2.01268978e-02\n",
      " -3.48802321e-02  1.08891696e-01  5.88038042e-02 -3.89922187e-02\n",
      "  3.36642377e-02  1.05792722e-02  8.49163719e-03  3.97885703e-02\n",
      " -2.69124787e-02  1.85097888e-04 -1.55662410e-02 -1.32741604e-08\n",
      " -2.76458655e-02 -2.64894888e-02  5.21918423e-02 -4.39955713e-03\n",
      " -5.72559573e-02  8.06644838e-03 -6.11751713e-02  5.19004390e-02\n",
      "  1.94031056e-02 -3.33748274e-02  1.02931581e-01 -6.08338639e-02\n",
      " -2.60585658e-02  7.29072094e-02 -1.97213963e-02  9.49576776e-03\n",
      " -4.17649448e-02  6.39799386e-02 -2.02614870e-02  7.35600479e-03\n",
      "  1.06311496e-02  1.09668463e-01  3.97427827e-02 -3.77682596e-02\n",
      " -1.42840333e-02  8.27386323e-03 -1.81734618e-02  6.04460910e-02\n",
      "  6.41397014e-02 -4.97442763e-03 -7.96292815e-03  9.47823524e-02\n",
      "  7.23205134e-02 -9.46987569e-02  8.98355320e-02  6.52121156e-02\n",
      " -2.73668431e-02  8.95731896e-02  9.72146168e-03  8.82105231e-02\n",
      "  1.09039871e-02  3.47837396e-02 -4.35143709e-02 -5.25180437e-02\n",
      "  9.54336897e-02 -5.21123235e-04 -4.24972884e-02 -7.75361201e-03\n",
      " -2.05312688e-02 -3.98563668e-02  1.87598541e-02 -4.64451499e-02\n",
      " -3.64347510e-02  1.52264778e-02  1.74199156e-02  4.76582721e-02\n",
      "  1.00018485e-02 -8.16244856e-02 -6.68503717e-03  2.16668248e-02\n",
      "  1.03062004e-01 -1.72485206e-02 -6.39785603e-02  3.88544798e-02]\n"
     ]
    }
   ],
   "source": [
    "query = \"Benchmark\"\n",
    "query_emb = model.encode(query)\n",
    "print(query_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23d39fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity([query_emb], hierarchical_docs_df['embedding'].tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb9c25c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 documentos más similares:\n",
      "1. Doc 39: 0.3310 - Heaps' law: Estimating the number of terms\n",
      "2. Doc 187: 0.3094 - References and further reading\n",
      "3. Doc 81: 0.2841 - System issues\n",
      "4. Doc 41: 0.2804 - Dictionary compression\n",
      "5. Doc 76: 0.2746 - Standard test collections\n",
      "6. Doc 143: 0.2741 - Time complexity and optimality of kNN\n",
      "7. Doc 148: 0.2624 - Exercises\n",
      "8. Doc 195: 0.2615 - Near-duplicates and shingling\n",
      "9. Doc 68: 0.2478 - Tiered indexes\n",
      "10. Doc 201: 0.2470 - The URL frontier\n"
     ]
    }
   ],
   "source": [
    "# Obtener los índices ordenados por similitud (de mayor a menor)\n",
    "sorted_indices = similarities.argsort()[::-1]\n",
    "\n",
    "print(\"Top 10 documentos más similares:\")\n",
    "for i in range(10):\n",
    "    idx = sorted_indices[i]\n",
    "    similarity = similarities[idx]\n",
    "    title = hierarchical_docs_df.iloc[idx]['title']\n",
    "    print(f\"{i+1}. Doc {idx+1}: {similarity:.4f} - {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ff2dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d4c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feb9cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREGUNTA: What is the benchmark for information retrieval?\n",
      "\n",
      "RESPUESTA:\n",
      "El benchmark para information retrieval se refiere a colecciones de prueba estándar y evaluaciones que permiten medir cuantitativamente la efectividad de los sistemas de recuperación de información. Un ejemplo destacado es la Text Retrieval Conference (TREC), organizada por el National Institute of Standards and Technology (NIST) desde 1992, que proporciona una serie de colecciones de prueba y pistas para evaluar sistemas de recuperación de información (Documento 89). También se menciona la colección Cranfield, pionera en permitir medidas cuantitativas precisas, aunque actualmente es demasiado pequeña para experimentos avanzados (Documento 89).\n",
      "\n",
      "Por lo tanto, el benchmark para information retrieval son estas colecciones de prueba estándar como TREC y Cranfield, que permiten evaluar y comparar el rendimiento de los sistemas de recuperación de información.\n",
      "\n",
      "DOCUMENTOS UTILIZADOS: 10\n",
      "\n",
      "DOCUMENTOS CONSULTADOS:\n",
      "1. Documento 45: Heaps' law: Estimating the number of terms (Similitud: 0.3310)\n",
      "2. Documento 218: References and further reading (Similitud: 0.3094)\n",
      "3. Documento 95: System issues (Similitud: 0.2841)\n",
      "4. Documento 47: Dictionary compression (Similitud: 0.2804)\n",
      "5. Documento 89: Standard test collections (Similitud: 0.2746)\n",
      "6. Documento 170: Time complexity and optimality of kNN (Similitud: 0.2741)\n",
      "7. Documento 175: Exercises (Similitud: 0.2624)\n",
      "8. Documento 228: Near-duplicates and shingling (Similitud: 0.2615)\n",
      "9. Documento 81: Tiered indexes (Similitud: 0.2478)\n",
      "10. Documento 237: The URL frontier (Similitud: 0.2470)\n"
     ]
    }
   ],
   "source": [
    "def rag_query_with_openai(query, top_k=10):\n",
    "\n",
    "    # Obtener top k documentos más relevantes\n",
    "    sorted_indices = similarities.argsort()[::-1]\n",
    "    \n",
    "    # Preparar contexto con los documentos más relevantes\n",
    "    context_docs = []\n",
    "    for i in range(min(top_k, len(sorted_indices))):\n",
    "        idx = sorted_indices[i]\n",
    "        doc_info = hierarchical_docs_df.iloc[idx]\n",
    "        context_docs.append({\n",
    "            'doc_id': doc_info['doc_id'],  # Agregar el doc_id real\n",
    "            'title': doc_info['title'],\n",
    "            'content': doc_info['content'][:2000],  # Limitar contenido para no exceder tokens\n",
    "            'similarity': similarities[idx]\n",
    "        })\n",
    "    \n",
    "    # Construir el prompt con contexto\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"DOCUMENTO {doc['doc_id']}: {doc['title']}\\n{doc['content']}\"\n",
    "        for i, doc in enumerate(context_docs)\n",
    "    ])\n",
    "    \n",
    "    # 6. Hacer la consulta a OpenAI\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Eres un asistente especializado en Information Retrieval. \"\n",
    "                \"Responde únicamente basándote en los documentos proporcionados. \"\n",
    "                \"Si no encuentras información relevante en los documentos, di claramente que no sabes o \"\n",
    "                \"que la información no está disponible en los documentos. \"\n",
    "                \"NO inventes ni agregues información externa.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Basándote ÚNICAMENTE en los siguientes documentos, \n",
    "                responde a la pregunta: \"{query}\"\n",
    "\n",
    "DOCUMENTOS DE REFERENCIA:\n",
    "{context_text}\n",
    "\n",
    "PREGUNTA: {query}\n",
    "\n",
    "INSTRUCCIONES:\n",
    "- Responde solo con información que esté explícitamente en los documentos\n",
    "- Si no hay información suficiente, di \"No encuentro información suficiente en los documentos proporcionados\"\n",
    "- Cita el número de documento cuando sea relevante\n",
    "- Sé preciso y conciso\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'answer': completion.choices[0].message.content,\n",
    "        'relevant_docs': context_docs,\n",
    "        'num_docs_used': len(context_docs)\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso\n",
    "query = \"What is the benchmark for information retrieval?\"\n",
    "result = rag_query_with_openai(query, top_k=10)\n",
    "\n",
    "print(f\"PREGUNTA: {result['query']}\")\n",
    "print(f\"\\nRESPUESTA:\")\n",
    "print(result['answer'])\n",
    "print(f\"\\nDOCUMENTOS UTILIZADOS: {result['num_docs_used']}\")\n",
    "\n",
    "# Mostrar qué documentos específicos se usaron\n",
    "print(f\"\\nDOCUMENTOS CONSULTADOS:\")\n",
    "for i, doc in enumerate(result['relevant_docs']):\n",
    "    print(f\"{i+1}. Documento {doc['doc_id']}: {doc['title']} (Similitud: {doc['similarity']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6522946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Indirect relevance feedback\n",
      "\n",
      "Contenido (primeros 500 caracteres):\n",
      "Online edition (c)\n",
      "2009 Cambridge UP\n",
      "9.1\n",
      "Relevance feedback and pseudo relevance feedback\n",
      "187\n",
      "Precision at k = 50\n",
      "Term weighting\n",
      "no RF\n",
      "pseudo RF\n",
      "lnc.ltc\n",
      "64.2%\n",
      "72.7%\n",
      "Lnu.ltu\n",
      "74.2%\n",
      "87.0%\n",
      "◮Figure 9.5\n",
      "Results showing pseudo relevance feedback greatly improving perfor-\n",
      "mance. These results are taken from the Cornell SMART system at TREC 4 (Buckley\n",
      "et al. 1995), and also contrast the use of two different length normalization schemes\n",
      "(L vs. l); cf. Figure 6.15 (page 128). Pseudo relevance feedback cons\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el contenido del documento en la posición 45\n",
    "print(\"Título:\", hierarchical_docs_df.iloc[89]['title'])\n",
    "print(\"\\nContenido (primeros 500 caracteres):\")\n",
    "print(hierarchical_docs_df.iloc[89]['content'][:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
